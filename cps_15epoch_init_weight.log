


************************************************************************************************************************************************************************************************************
**************************** Run: run.py | Framework: PyTorch | Method: rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres | Version: 3 | Data: CholecT50 | Batch: 32 ****************************
*** Time: Sun Mar 19 10:03:50 2023 | Start: 0-epoch  0-steps | Init CKPT: None | Save CKPT: /home/jhuangcj/tom/rend/__checkpoint__/run_3/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth ***
****** LR Config: Init_l: [0.01, 0.01, 0.01] | Init_l: [0.01, 0.01, 0.01] | Peak: [0.1, 0.1, 0.1] | Warmup Epoch: [9, 18, 58] | Rise: 0.1 | Decay 0.99 | train params 34240662 | all params 34240662 ******
************************************************************************************************************************************************************************************************************
Traning | lr_l: [[0.01], [0.01], [0.01]] | lr_r: [[0.01], [0.01], [0.01]] | epoch 0 | completed | cps_loss => i: [1.2808] v: [1.3459] t: [1.3296] ivt: [1.3813] >> eta: 2418.61 secs
completed | sup_loss_l => i: [0.3263] v: [0.2907] t: [0.3869] ivt: [0.0457] >> eta: 2418.61 secs
completed | sup_loss_r => i: [0.3418] v: [0.4506] t: [0.3240] ivt: [0.0453] >> eta: 2418.61 secs
Evaluating @ epoch:  0
>>> Saving checkpoint for epoch 1 at /home/jhuangcj/tom/rend/__checkpoint__/run_3/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth, time Sun Mar 19 10:46:10 2023 
				 video-wise | eta 120.92 secs | mAP_l => ivt: [0.04164] | mAP_r => ivt: [0.04051] 
Traning | lr_l: [[0.02], [0.015], [0.011551724137931034]] | lr_r: [[0.02], [0.015], [0.011551724137931034]] | epoch 1 | completed | cps_loss => i: [1.2709] v: [1.3229] t: [1.3236] ivt: [1.3809] >> eta: 2373.14 secs
completed | sup_loss_l => i: [0.3440] v: [0.2524] t: [0.2115] ivt: [0.0540] >> eta: 2373.14 secs
completed | sup_loss_r => i: [0.3885] v: [0.2629] t: [0.1941] ivt: [0.0523] >> eta: 2373.14 secs
Evaluating @ epoch:  1
>>> Saving checkpoint for epoch 2 at /home/jhuangcj/tom/rend/__checkpoint__/run_3/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth, time Sun Mar 19 11:26:27 2023 
				 video-wise | eta 44.12 secs | mAP_l => ivt: [0.04726] | mAP_r => ivt: [0.04314] 
Traning | lr_l: [[0.03], [0.019999999999999997], [0.013103448275862068]] | lr_r: [[0.03], [0.019999999999999997], [0.013103448275862068]] | epoch 2 | completed | cps_loss => i: [1.3273] v: [1.3251] t: [1.3236] ivt: [1.3841] >> eta: 2380.76 secs
completed | sup_loss_l => i: [0.2842] v: [0.1753] t: [0.1366] ivt: [0.0389] >> eta: 2380.76 secs
completed | sup_loss_r => i: [0.4131] v: [0.2187] t: [0.1431] ivt: [0.0446] >> eta: 2380.76 secs
Evaluating @ epoch:  2
				 video-wise | eta 42.77 secs | mAP_l => ivt: [0.05562] | mAP_r => ivt: [0.03911] 
Traning | lr_l: [[0.039999999999999994], [0.024999999999999994], [0.014655172413793103]] | lr_r: [[0.039999999999999994], [0.024999999999999994], [0.014655172413793103]] | epoch 3 | completed | cps_loss => i: [1.2483] v: [1.2939] t: [1.3175] ivt: [1.3828] >> eta: 2367.28 secs
completed | sup_loss_l => i: [0.1271] v: [0.1699] t: [0.1312] ivt: [0.0432] >> eta: 2367.28 secs
completed | sup_loss_r => i: [0.2199] v: [0.1989] t: [0.1382] ivt: [0.0478] >> eta: 2367.28 secs
Evaluating @ epoch:  3
>>> Saving checkpoint for epoch 4 at /home/jhuangcj/tom/rend/__checkpoint__/run_3/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth, time Sun Mar 19 12:47:03 2023 
				 video-wise | eta 44.50 secs | mAP_l => ivt: [0.08559] | mAP_r => ivt: [0.05631] 
Traning | lr_l: [[0.04999999999999999], [0.029999999999999992], [0.016206896551724137]] | lr_r: [[0.04999999999999999], [0.029999999999999992], [0.016206896551724137]] | epoch 4 | completed | cps_loss => i: [1.2699] v: [1.3092] t: [1.3242] ivt: [1.3846] >> eta: 2382.62 secs
completed | sup_loss_l => i: [0.1537] v: [0.1177] t: [0.1577] ivt: [0.0428] >> eta: 2382.62 secs
completed | sup_loss_r => i: [0.2172] v: [0.1475] t: [0.1759] ivt: [0.0478] >> eta: 2382.62 secs
Evaluating @ epoch:  4
				 video-wise | eta 43.00 secs | mAP_l => ivt: [0.11637] | mAP_r => ivt: [0.06614] 
Traning | lr_l: [[0.059999999999999984], [0.03499999999999999], [0.017758620689655173]] | lr_r: [[0.059999999999999984], [0.03499999999999999], [0.017758620689655173]] | epoch 5 | completed | cps_loss => i: [1.2642] v: [1.3135] t: [1.3304] ivt: [1.3854] >> eta: 2354.04 secs
completed | sup_loss_l => i: [0.1441] v: [0.1212] t: [0.0895] ivt: [0.0404] >> eta: 2354.04 secs
completed | sup_loss_r => i: [0.2743] v: [0.1710] t: [0.1027] ivt: [0.0462] >> eta: 2354.04 secs
Evaluating @ epoch:  5
				 video-wise | eta 43.43 secs | mAP_l => ivt: [0.11739] | mAP_r => ivt: [0.06106] 
Traning | lr_l: [[0.06999999999999998], [0.03999999999999999], [0.019310344827586208]] | lr_r: [[0.06999999999999998], [0.03999999999999999], [0.019310344827586208]] | epoch 6 | completed | cps_loss => i: [1.2676] v: [1.3060] t: [1.3337] ivt: [1.3839] >> eta: 2382.80 secs
completed | sup_loss_l => i: [0.0855] v: [0.1092] t: [0.1244] ivt: [0.0396] >> eta: 2382.80 secs
completed | sup_loss_r => i: [0.1610] v: [0.1492] t: [0.1330] ivt: [0.0444] >> eta: 2382.80 secs
Evaluating @ epoch:  6
				 video-wise | eta 59.19 secs | mAP_l => ivt: [0.13184] | mAP_r => ivt: [0.07550] 
Traning | lr_l: [[0.07999999999999997], [0.044999999999999984], [0.02086206896551724]] | lr_r: [[0.07999999999999997], [0.044999999999999984], [0.02086206896551724]] | epoch 7 | completed | cps_loss => i: [1.3270] v: [1.3575] t: [1.3419] ivt: [1.3874] >> eta: 2523.41 secs
completed | sup_loss_l => i: [0.1262] v: [0.0980] t: [0.0838] ivt: [0.0324] >> eta: 2523.41 secs
completed | sup_loss_r => i: [0.3004] v: [0.1899] t: [0.1204] ivt: [0.0431] >> eta: 2523.41 secs
Evaluating @ epoch:  7
				 video-wise | eta 68.59 secs | mAP_l => ivt: [0.14330] | mAP_r => ivt: [0.04485] 
Traning | lr_l: [[0.08999999999999997], [0.04999999999999998], [0.022413793103448276]] | lr_r: [[0.08999999999999997], [0.04999999999999998], [0.022413793103448276]] | epoch 8 | completed | cps_loss => i: [1.2574] v: [1.3275] t: [1.3383] ivt: [1.3846] >> eta: 2351.50 secs
completed | sup_loss_l => i: [0.1195] v: [0.1070] t: [0.0835] ivt: [0.0291] >> eta: 2351.50 secs
completed | sup_loss_r => i: [0.2092] v: [0.1754] t: [0.1034] ivt: [0.0368] >> eta: 2351.50 secs
Evaluating @ epoch:  8
				 video-wise | eta 44.71 secs | mAP_l => ivt: [0.15093] | mAP_r => ivt: [0.06979] 
Traning | lr_l: [[0.09999999999999996], [0.054999999999999986], [0.02396551724137931]] | lr_r: [[0.09999999999999996], [0.054999999999999986], [0.02396551724137931]] | epoch 9 | completed | cps_loss => i: [1.2368] v: [1.2921] t: [1.3428] ivt: [1.3874] >> eta: 2362.60 secs
completed | sup_loss_l => i: [0.1669] v: [0.1078] t: [0.0864] ivt: [0.0388] >> eta: 2362.60 secs
completed | sup_loss_r => i: [0.2095] v: [0.1433] t: [0.1046] ivt: [0.0428] >> eta: 2362.60 secs
Evaluating @ epoch:  9
				 video-wise | eta 44.06 secs | mAP_l => ivt: [0.16069] | mAP_r => ivt: [0.08288] 
Traning | lr_l: [[0.09999999999999999], [0.059999999999999984], [0.025517241379310347]] | lr_r: [[0.09999999999999999], [0.059999999999999984], [0.025517241379310347]] | epoch 10 | completed | cps_loss => i: [1.2401] v: [1.2995] t: [1.3419] ivt: [1.3832] >> eta: 2369.73 secs
completed | sup_loss_l => i: [0.1182] v: [0.1283] t: [0.1107] ivt: [0.0414] >> eta: 2369.73 secs
completed | sup_loss_r => i: [0.1656] v: [0.1702] t: [0.1391] ivt: [0.0474] >> eta: 2369.73 secs
Evaluating @ epoch:  10
>>> Saving checkpoint for epoch 11 at /home/jhuangcj/tom/rend/__checkpoint__/run_3/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth, time Sun Mar 19 17:31:41 2023 
				 video-wise | eta 45.04 secs | mAP_l => ivt: [0.14924] | mAP_r => ivt: [0.09231] 
Traning | lr_l: [[0.09899999999999999], [0.06499999999999997], [0.02706896551724138]] | lr_r: [[0.09899999999999999], [0.06499999999999997], [0.02706896551724138]] | epoch 11 | completed | cps_loss => i: [1.2147] v: [1.2835] t: [1.3454] ivt: [1.3845] >> eta: 2421.90 secs
completed | sup_loss_l => i: [0.0937] v: [0.0737] t: [0.0809] ivt: [0.0328] >> eta: 2421.90 secs
completed | sup_loss_r => i: [0.1351] v: [0.1014] t: [0.1098] ivt: [0.0371] >> eta: 2421.90 secs
Evaluating @ epoch:  11
				 video-wise | eta 128.46 secs | mAP_l => ivt: [0.16668] | mAP_r => ivt: [0.09146] 
Traning | lr_l: [[0.09800999999999999], [0.06999999999999997], [0.028620689655172414]] | lr_r: [[0.09800999999999999], [0.06999999999999997], [0.028620689655172414]] | epoch 12 | completed | cps_loss => i: [1.2285] v: [1.2934] t: [1.3392] ivt: [1.3831] >> eta: 2616.56 secs
completed | sup_loss_l => i: [0.0695] v: [0.0900] t: [0.0703] ivt: [0.0222] >> eta: 2616.56 secs
completed | sup_loss_r => i: [0.1299] v: [0.1398] t: [0.0914] ivt: [0.0302] >> eta: 2616.56 secs
Evaluating @ epoch:  12
				 video-wise | eta 53.12 secs | mAP_l => ivt: [0.18114] | mAP_r => ivt: [0.11682] 
Traning | lr_l: [[0.09702989999999999], [0.07499999999999996], [0.03017241379310345]] | lr_r: [[0.09702989999999999], [0.07499999999999996], [0.03017241379310345]] | epoch 13 | completed | cps_loss => i: [1.2399] v: [1.2772] t: [1.3292] ivt: [1.3838] >> eta: 2705.89 secs
completed | sup_loss_l => i: [0.1083] v: [0.1146] t: [0.1501] ivt: [0.0401] >> eta: 2705.89 secs
completed | sup_loss_r => i: [0.2131] v: [0.1755] t: [0.1629] ivt: [0.0490] >> eta: 2705.89 secs
Evaluating @ epoch:  13
				 video-wise | eta 78.75 secs | mAP_l => ivt: [0.17477] | mAP_r => ivt: [0.12521] 
Traning | lr_l: [[0.096059601], [0.07999999999999995], [0.031724137931034485]] | lr_r: [[0.096059601], [0.07999999999999995], [0.031724137931034485]] | epoch 14 | completed | cps_loss => i: [1.2392] v: [1.2831] t: [1.3429] ivt: [1.3838] >> eta: 2667.18 secs
completed | sup_loss_l => i: [0.0753] v: [0.0599] t: [0.0693] ivt: [0.0225] >> eta: 2667.18 secs
completed | sup_loss_r => i: [0.0964] v: [0.0736] t: [0.0935] ivt: [0.0314] >> eta: 2667.18 secs
Evaluating @ epoch:  14
				 video-wise | eta 124.01 secs | mAP_l => ivt: [0.17548] | mAP_r => ivt: [0.14537] 
--------------------------------------------------
Test Results of 1st subnetwork
Per-category AP: 
I   : [0.96251718 0.87670224 0.97699595 0.55356154 0.7691787  0.74352101]
V   : [0.65214219 0.92863283 0.93665151 0.75510808 0.70491225 0.23868413
 0.4567826  0.26129077 0.31957047 0.23121064]
T   : [0.86815023 0.15836405 0.26406324 0.25418718 0.01158133        nan
 0.44150941 0.12317458 0.4754662  0.70911354 0.28650572 0.03599324
 0.07454055 0.81669614 0.24185928]
IV  : [0.66466352 0.87523398 0.00579166 0.0896171  0.21243492 0.04368373
 0.03239978 0.1172927  0.79979501 0.03140423 0.03321229 0.93444122
 0.00987979        nan 0.10103154        nan        nan 0.32300239
 0.01467446 0.65241009 0.04540053 0.06835996        nan 0.38042766
 0.15906914 0.10992543]
IT  : [0.73803386 0.1546232  0.05503843 0.01534986        nan 0.45827703
 0.27365687 0.04519613 0.04209154 0.82161691 0.21243492 0.24094915
 0.21231567 0.03270697        nan 0.01687624        nan 0.59760423
 0.72109147        nan 0.11733105        nan        nan 0.03140423
 0.7412063  0.13986916 0.21181357 0.09182525        nan        nan
 0.00921524 0.4030829  0.04157192 0.10103154        nan 0.02515686
 0.25142396 0.13559714        nan 0.08164259 0.10509357        nan
        nan 0.01467446 0.0240049  0.41255933 0.34275332        nan
        nan 0.04540053        nan        nan        nan 0.01653616
 0.38042766 0.09952906 0.13835427        nan 0.10992543]
IVT : [       nan 0.00811116 0.00204499 0.01534986 0.06611824        nan
 0.01390962 0.19869313 0.00295127 0.0203342  0.02266359        nan
 0.82161691 0.0896171         nan        nan 0.22295039 0.7453838
 0.04167864 0.46012521 0.2696327  0.04911905 0.59760423        nan
        nan 0.01568184 0.01723269 0.21254563 0.10294929 0.69328141
 0.25950454        nan        nan        nan 0.00406635        nan
 0.13054367        nan 0.01185279 0.04190118        nan 0.00777914
        nan        nan 0.03332031 0.03149938        nan        nan
        nan        nan        nan 0.00394263 0.00359319 0.00793939
        nan        nan        nan 0.09183361 0.21186046 0.13988187
 0.73565888 0.38511746 0.04180328 0.03126914 0.00778974        nan
 0.10509357        nan 0.13559714 0.25142396 0.11532737 0.08164259
        nan        nan        nan        nan        nan        nan
 0.34275332 0.41255933        nan 0.0240049  0.38042766        nan
        nan        nan        nan        nan 0.09952906 0.00517708
 0.05994714        nan 0.06948851        nan 0.21243492 0.03140423
 0.10103154 0.01467446 0.04540053 0.10992543]
--------------------------------------------------
Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT 
:::::: : 0.8137 | 0.5485 | 0.3401 | 0.2593 | 0.2124 | 0.1552 
==================================================
--------------------------------------------------
Test Results of 2nd subnetwork
Per-category AP: 
I   : [0.94206104 0.85547206 0.96667496 0.15531589 0.50526613 0.60020259]
V   : [0.39208007 0.8959728  0.91440195 0.65684111 0.44791703 0.13484015
 0.33152904 0.14850868 0.07140493 0.19001453]
T   : [0.84088529 0.07061384 0.25789454 0.14289211 0.01209924        nan
 0.34967182 0.06435261 0.40018731 0.05500932 0.13497085 0.04279011
 0.03967833 0.32487964 0.14474879]
IV  : [0.34555521 0.88975829 0.00256249 0.0174312  0.15038715 0.06332562
 0.09011123 0.0343787  0.62101553 0.0259161  0.01141443 0.91039519
 0.00821678        nan 0.06827818        nan        nan 0.09445921
 0.01169284 0.22138376 0.0346037  0.04324532        nan 0.26599099
 0.05247589 0.06905394]
IT  : [0.76613506 0.0491542  0.03126509 0.01989516        nan 0.32846258
 0.18263589 0.03829952 0.03291624 0.33930869 0.15038715 0.0624921
 0.13605254 0.02513018        nan 0.02187415        nan 0.02146765
 0.58843528        nan 0.12061533        nan        nan 0.0259161
 0.61234008 0.19400023 0.1783276  0.12088964        nan        nan
 0.00560167 0.14772105 0.02521224 0.06827818        nan 0.01905695
 0.03896183 0.07087025        nan 0.06828597 0.11447184        nan
        nan 0.01169284 0.02823994 0.12845842 0.07281119        nan
        nan 0.0346037         nan        nan        nan 0.00255769
 0.26599099 0.02623707 0.06062616        nan 0.06905394]
IVT : [       nan 0.00461942 0.00401606 0.01989516 0.03240533        nan
 0.01017951 0.02742405 0.00279631 0.03308345 0.01783721        nan
 0.33930869 0.0174312         nan        nan 0.06682093 0.76671954
 0.03272466 0.32536622 0.18187771 0.03864756 0.02146765        nan
        nan 0.05297275 0.0218786  0.13593351 0.05607894 0.54634232
 0.11874795        nan        nan        nan 0.00664982        nan
 0.03036599        nan 0.00535438 0.05946248        nan 0.00546296
        nan        nan 0.09283032 0.02655084        nan        nan
        nan        nan        nan 0.00873458 0.00217846 0.01828466
        nan        nan        nan 0.12088964 0.17838925 0.19438358
 0.6016479  0.13613967 0.02521546 0.0099196  0.01181689        nan
 0.11447184        nan 0.07087025 0.03896183 0.01467063 0.06828597
        nan        nan        nan        nan        nan        nan
 0.07281119 0.12845842        nan 0.02823994 0.26599099        nan
        nan        nan        nan        nan 0.02623707 0.00360096
 0.04400522        nan 0.04326605        nan 0.15038715 0.0259161
 0.06827818 0.01169284 0.0346037  0.06905394]
--------------------------------------------------
Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT 
:::::: : 0.6708 | 0.4184 | 0.2058 | 0.1833 | 0.1294 | 0.0933 
==================================================
All done!
Shutting done...
It is what it is ...
C'est finis! ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
