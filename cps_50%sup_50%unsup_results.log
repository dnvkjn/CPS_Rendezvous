


********************************************************************************************************************************************************************************************************************************************************************************************************************
******************************************************************************** Run: run.py | Framework: PyTorch | Method: rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres | Version: 3 | Data: CholecT50 | Batch: 32 ********************************************************************************
*** Time: Fri Apr  7 23:06:16 2023 | Start: 0-epoch  0-steps | Init CKPT: /home/jhuangcj/tom/rend/__checkpoint__/run_3/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth | Save CKPT: /home/jhuangcj/tom/rend/__checkpoint__/run_3/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth ***
********************************************************** LR Config: Init_l: [0.01, 0.01, 0.01] | Init_r: [0.01, 0.01, 0.01] | Peak: [0.1, 0.1, 0.1] | Warmup Epoch: [9, 18, 58] | Rise: 0.1 | Decay 0.99 | train params 34240662 | all params 34240662 **********************************************************
********************************************************************************************************************************************************************************************************************************************************************************************************************
Traning | lr_l: [[0.01], [0.01], [0.01]] | lr_r: [[0.01], [0.01], [0.01]] | epoch 0 | completed | cps_loss => i: [1.2252] v: [1.2729] t: [1.3302] ivt: [1.3815] >> eta: 2591.03 secs
completed | sup_loss_l => i: [0.0306] v: [0.0276] t: [0.0603] ivt: [0.0122] >> eta: 2591.03 secs
completed | sup_loss_r => i: [0.0459] v: [0.0481] t: [0.0703] ivt: [0.0189] >> eta: 2591.04 secs
Evaluating @ epoch:  0
>>> Saving checkpoint for epoch 1 at /home/jhuangcj/tom/rend/__checkpoint__/run_3/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth, time Fri Apr  7 23:50:13 2023 
				 video-wise | eta 46.07 secs | mAP_l => ivt: [0.20454] | mAP_r => ivt: [0.18134] 
Traning | lr_l: [[0.02], [0.015], [0.011551724137931034]] | lr_r: [[0.02], [0.015], [0.011551724137931034]] | epoch 1 | completed | cps_loss => i: [1.2261] v: [1.2768] t: [1.3339] ivt: [1.3820] >> eta: 2550.00 secs
completed | sup_loss_l => i: [0.0306] v: [0.0460] t: [0.0751] ivt: [0.0191] >> eta: 2550.00 secs
completed | sup_loss_r => i: [0.0538] v: [0.0651] t: [0.0713] ivt: [0.0225] >> eta: 2550.00 secs
Evaluating @ epoch:  1
				 video-wise | eta 44.48 secs | mAP_l => ivt: [0.20040] | mAP_r => ivt: [0.17731] 
Traning | lr_l: [[0.03], [0.019999999999999997], [0.013103448275862068]] | lr_r: [[0.03], [0.019999999999999997], [0.013103448275862068]] | epoch 2 | completed | cps_loss => i: [1.2114] v: [1.2677] t: [1.3248] ivt: [1.3799] >> eta: 2539.98 secs
completed | sup_loss_l => i: [0.0581] v: [0.0451] t: [0.0508] ivt: [0.0149] >> eta: 2539.98 secs
completed | sup_loss_r => i: [0.0440] v: [0.0512] t: [0.0644] ivt: [0.0202] >> eta: 2539.98 secs
Evaluating @ epoch:  2
				 video-wise | eta 45.66 secs | mAP_l => ivt: [0.20235] | mAP_r => ivt: [0.18423] 
Traning | lr_l: [[0.039999999999999994], [0.024999999999999994], [0.014655172413793103]] | lr_r: [[0.039999999999999994], [0.024999999999999994], [0.014655172413793103]] | epoch 3 | completed | cps_loss => i: [1.2010] v: [1.2626] t: [1.3289] ivt: [1.3808] >> eta: 2545.91 secs
completed | sup_loss_l => i: [0.0212] v: [0.0332] t: [0.0360] ivt: [0.0125] >> eta: 2545.92 secs
completed | sup_loss_r => i: [0.0314] v: [0.0410] t: [0.0532] ivt: [0.0165] >> eta: 2545.92 secs
Evaluating @ epoch:  3
				 video-wise | eta 49.28 secs | mAP_l => ivt: [0.19787] | mAP_r => ivt: [0.17536] 
Traning | lr_l: [[0.04999999999999999], [0.029999999999999992], [0.016206896551724137]] | lr_r: [[0.04999999999999999], [0.029999999999999992], [0.016206896551724137]] | epoch 4 | completed | cps_loss => i: [1.2336] v: [1.2858] t: [1.3401] ivt: [1.3829] >> eta: 2549.30 secs
completed | sup_loss_l => i: [0.0363] v: [0.0422] t: [0.0696] ivt: [0.0267] >> eta: 2549.36 secs
completed | sup_loss_r => i: [0.0633] v: [0.0762] t: [0.0986] ivt: [0.0323] >> eta: 2549.36 secs
Evaluating @ epoch:  4
				 video-wise | eta 45.37 secs | mAP_l => ivt: [0.19954] | mAP_r => ivt: [0.16289] 
Traning | lr_l: [[0.059999999999999984], [0.03499999999999999], [0.017758620689655173]] | lr_r: [[0.059999999999999984], [0.03499999999999999], [0.017758620689655173]] | epoch 5 | completed | cps_loss => i: [1.2225] v: [1.2708] t: [1.3358] ivt: [1.3821] >> eta: 2558.04 secs
completed | sup_loss_l => i: [0.0232] v: [0.0503] t: [0.0644] ivt: [0.0184] >> eta: 2558.05 secs
completed | sup_loss_r => i: [0.0464] v: [0.0534] t: [0.0643] ivt: [0.0219] >> eta: 2558.05 secs
Evaluating @ epoch:  5
				 video-wise | eta 44.47 secs | mAP_l => ivt: [0.19293] | mAP_r => ivt: [0.17584] 
Traning | lr_l: [[0.06999999999999998], [0.03999999999999999], [0.019310344827586208]] | lr_r: [[0.06999999999999998], [0.03999999999999999], [0.019310344827586208]] | epoch 6 | completed | cps_loss => i: [1.2136] v: [1.2680] t: [1.3353] ivt: [1.3834] >> eta: 2545.22 secs
completed | sup_loss_l => i: [0.0878] v: [0.0633] t: [0.0948] ivt: [0.0180] >> eta: 2545.23 secs
completed | sup_loss_r => i: [0.0925] v: [0.0655] t: [0.1091] ivt: [0.0244] >> eta: 2545.23 secs
Evaluating @ epoch:  6
				 video-wise | eta 46.76 secs | mAP_l => ivt: [0.19121] | mAP_r => ivt: [0.17314] 
Traning | lr_l: [[0.07999999999999997], [0.044999999999999984], [0.02086206896551724]] | lr_r: [[0.07999999999999997], [0.044999999999999984], [0.02086206896551724]] | epoch 7 | completed | cps_loss => i: [1.2201] v: [1.2726] t: [1.3300] ivt: [1.3820] >> eta: 2552.62 secs
completed | sup_loss_l => i: [0.0367] v: [0.0690] t: [0.0765] ivt: [0.0198] >> eta: 2552.62 secs
completed | sup_loss_r => i: [0.0850] v: [0.0892] t: [0.0897] ivt: [0.0249] >> eta: 2552.62 secs
Evaluating @ epoch:  7
				 video-wise | eta 45.21 secs | mAP_l => ivt: [0.20616] | mAP_r => ivt: [0.18059] 
Traning | lr_l: [[0.08999999999999997], [0.04999999999999998], [0.022413793103448276]] | lr_r: [[0.08999999999999997], [0.04999999999999998], [0.022413793103448276]] | epoch 8 | completed | cps_loss => i: [1.2222] v: [1.2692] t: [1.3308] ivt: [1.3826] >> eta: 2532.53 secs
completed | sup_loss_l => i: [0.0397] v: [0.0355] t: [0.0496] ivt: [0.0147] >> eta: 2532.53 secs
completed | sup_loss_r => i: [0.0426] v: [0.0491] t: [0.0409] ivt: [0.0166] >> eta: 2532.53 secs
Evaluating @ epoch:  8
				 video-wise | eta 43.90 secs | mAP_l => ivt: [0.19696] | mAP_r => ivt: [0.16437] 
Traning | lr_l: [[0.09999999999999996], [0.054999999999999986], [0.02396551724137931]] | lr_r: [[0.09999999999999996], [0.054999999999999986], [0.02396551724137931]] | epoch 9 | completed | cps_loss => i: [1.2295] v: [1.2792] t: [1.3332] ivt: [1.3828] >> eta: 2574.01 secs
completed | sup_loss_l => i: [0.0643] v: [0.0814] t: [0.0732] ivt: [0.0202] >> eta: 2574.02 secs
completed | sup_loss_r => i: [0.0670] v: [0.1022] t: [0.0770] ivt: [0.0195] >> eta: 2574.02 secs
Evaluating @ epoch:  9
				 video-wise | eta 43.79 secs | mAP_l => ivt: [0.19321] | mAP_r => ivt: [0.16641] 
--------------------------------------------------
Test Results of 1st subnetwork
Per-category AP: 
I   : [0.95668648 0.89286427 0.97775481 0.58226304 0.84301888 0.77679782]
V   : [0.64906439 0.927832   0.94476628 0.79029895 0.78894857 0.52430257
 0.58986878 0.2937045  0.48197372 0.27436674]
T   : [0.9333369  0.12822048 0.42787764 0.30329505 0.10040595        nan
 0.59052457 0.1580289  0.63168024 0.32500274 0.57392488 0.09765639
 0.04824968 0.8171136  0.28069096]
IV  : [0.65521565 0.8957525  0.01266924 0.3820779  0.2290841  0.12075535
 0.112145   0.12393674 0.83046628 0.11676621 0.04785476 0.93324356
 0.01919572        nan 0.18901407        nan        nan 0.55512745
 0.04717229 0.74771328 0.19776479 0.13063872        nan 0.52320029
 0.21280315 0.13109599]
IT  : [0.86569477 0.09101355 0.06416748 0.01871112        nan 0.59578733
 0.60163645 0.18274183 0.08359997 0.8273255  0.2290841  0.24649796
 0.20117721 0.12269827        nan 0.60152647        nan 0.63040306
 0.82943711        nan 0.16624551        nan        nan 0.11676621
 0.79752799 0.19285873 0.36199011 0.26541686        nan        nan
 0.01895383 0.6237115  0.17962748 0.18901407        nan 0.12554766
 0.4982654  0.49639356        nan 0.12994653 0.0603912         nan
        nan 0.04717229 0.08968145 0.55324592 0.44832157        nan
        nan 0.19776479        nan        nan        nan 0.00594095
 0.52320029 0.15513573 0.17992183        nan 0.13109599]
IVT : [       nan 0.00431641 0.01886792 0.01871112 0.09832734        nan
 0.0383419  0.23142964 0.00187332 0.02156015 0.00493258        nan
 0.8273255  0.3820779         nan        nan 0.12518869 0.86879216
 0.08326687 0.59843267 0.60340429 0.18492915 0.63040306        nan
        nan 0.03454774 0.60836348 0.20370586 0.13251729 0.81518287
 0.45572312        nan        nan        nan 0.01627427        nan
 0.1056738         nan 0.00528063 0.0660401         nan 0.01449244
        nan        nan 0.16709842 0.04211749        nan        nan
        nan        nan        nan 0.01873263 0.01306893 0.03381918
        nan        nan        nan 0.26562596 0.36218391 0.19297186
 0.7909659  0.60730591 0.17965078 0.046207   0.02902621        nan
 0.0603912         nan 0.49639356 0.4982654  0.17313828 0.12994653
        nan        nan        nan        nan        nan        nan
 0.44832157 0.55324592        nan 0.08968145 0.52320029        nan
        nan        nan        nan        nan 0.15513573 0.01230982
 0.2500666         nan 0.14482401        nan 0.2290841  0.11676621
 0.18901407 0.04717229 0.19776479 0.13109599]
--------------------------------------------------
Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT 
:::::: : 0.8382 | 0.6265 | 0.3869 | 0.3279 | 0.3109 | 0.2360 
==================================================
--------------------------------------------------
Test Results of 2nd subnetwork
Per-category AP: 
I   : [0.95807948 0.88876516 0.97741423 0.56954407 0.77320696 0.77771228]
V   : [0.64962068 0.93075949 0.94312965 0.75758782 0.69518351 0.50910989
 0.53940956 0.19218011 0.53007803 0.22950666]
T   : [0.92061062 0.14563034 0.39062822 0.2019631  0.18014388        nan
 0.55062541 0.09294336 0.60861623 0.20763194 0.58829987 0.22684235
 0.05388402 0.8056746  0.20329194]
IV  : [0.65162837 0.90968803 0.00389938 0.18551223 0.18798471 0.17790324
 0.14141631 0.17432241 0.76099458 0.07506767 0.02619585 0.92453566
 0.01313883        nan 0.12582601        nan        nan 0.44809358
 0.02265937 0.6884671  0.06542234 0.13300247        nan 0.55639332
 0.14095722 0.17168846]
IT  : [0.86124024 0.34532793 0.0436504  0.02030942        nan 0.58799933
 0.53239735 0.19177864 0.05355175 0.83389259 0.18798471 0.30738524
 0.18747307 0.35190067        nan 0.57777105        nan 0.4422592
 0.72829009        nan 0.19418913        nan        nan 0.07506767
 0.76912314 0.20006907 0.34168728 0.18705863        nan        nan
 0.00729898 0.54376713 0.10629453 0.12582601        nan 0.09720347
 0.30179398 0.49869894        nan 0.16790159 0.13284425        nan
        nan 0.02265937 0.00575486 0.45664536 0.4177552         nan
        nan 0.06542234        nan        nan        nan 0.00339156
 0.55639332 0.09494018 0.1681151         nan 0.17168846]
IVT : [       nan 0.00734526 0.03333333 0.02030942 0.01993374        nan
 0.00855654 0.20568092 0.00284007 0.01751337 0.06912468        nan
 0.83389259 0.18551223        nan        nan 0.49660151 0.8647291
 0.05327565 0.5903865  0.53028539 0.1933553  0.4422592         nan
        nan 0.03932267 0.57765754 0.19385115 0.17029765 0.70128803
 0.52125451        nan        nan        nan 0.00654941        nan
 0.20179857        nan 0.00185673 0.13077896        nan 0.05754704
        nan        nan 0.1099529  0.18324913        nan        nan
        nan        nan        nan 0.02482052 0.00304828 0.01115948
        nan        nan        nan 0.18708212 0.34171269 0.20008137
 0.76561322 0.5260001  0.10635252 0.02039946 0.01499249        nan
 0.13284425        nan 0.49869894 0.30179398 0.04447584 0.16790159
        nan        nan        nan        nan        nan        nan
 0.4177552  0.45664536        nan 0.00575486 0.55639332        nan
        nan        nan        nan        nan 0.09494018 0.00580828
 0.22603147        nan 0.13657013        nan 0.18798471 0.07506767
 0.12582601 0.02265937 0.06542234 0.17168846]
--------------------------------------------------
Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT 
:::::: : 0.8241 | 0.5977 | 0.3698 | 0.2993 | 0.2918 | 0.2191 
==================================================
All done!
Shutting done...
It is what it is ...
C'est finis! --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
