


************************************************************************************************************************************************************************************************************
**************************** Run: run.py | Framework: PyTorch | Method: rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres | Version: 2 | Data: CholecT50 | Batch: 32 ****************************
*** Time: Fri Mar 17 11:51:59 2023 | Start: 0-epoch  0-steps | Init CKPT: None | Save CKPT: /home/jhuangcj/tom/rend/__checkpoint__/run_2/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth ***
****** LR Config: Init_l: [0.01, 0.01, 0.01] | Init_l: [0.01, 0.01, 0.01] | Peak: [0.1, 0.1, 0.1] | Warmup Epoch: [9, 18, 58] | Rise: 0.1 | Decay 0.99 | train params 34240662 | all params 34240662 ******
************************************************************************************************************************************************************************************************************
Traning | lr_l: [[0.01], [0.01], [0.01]] | lr_r: [[0.01], [0.01], [0.01]] | epoch 0 | completed | cps_loss => i: [1.2667] v: [1.2886] t: [1.3472] ivt: [1.3827] >> eta: 2429.16 secs
completed | sup_loss_l => i: [0.3294] v: [0.3337] t: [0.3131] ivt: [0.0391] >> eta: 2429.16 secs
completed | sup_loss_r => i: [0.3509] v: [0.4774] t: [0.5976] ivt: [0.0407] >> eta: 2429.16 secs
Evaluating @ epoch:  0
>>> Saving checkpoint for epoch 1 at /home/jhuangcj/tom/rend/__checkpoint__/run_2/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth, time Fri Mar 17 12:34:30 2023 
				 video-wise | eta 121.61 secs | mAP_l => ivt: [0.04698] | mAP_r => ivt: [0.04159] 
Traning | lr_l: [[0.02], [0.015], [0.011551724137931034]] | lr_r: [[0.02], [0.015], [0.011551724137931034]] | epoch 1 | completed | cps_loss => i: [1.2455] v: [1.2976] t: [1.3214] ivt: [1.3848] >> eta: 2380.96 secs
completed | sup_loss_l => i: [0.2236] v: [0.2101] t: [0.1434] ivt: [0.0397] >> eta: 2380.96 secs
completed | sup_loss_r => i: [0.2568] v: [0.2792] t: [0.3000] ivt: [0.0424] >> eta: 2380.96 secs
Evaluating @ epoch:  1
				 video-wise | eta 44.17 secs | mAP_l => ivt: [0.06300] | mAP_r => ivt: [0.04514] 
Traning | lr_l: [[0.03], [0.019999999999999997], [0.013103448275862068]] | lr_r: [[0.03], [0.019999999999999997], [0.013103448275862068]] | epoch 2 | completed | cps_loss => i: [1.2694] v: [1.3456] t: [1.3326] ivt: [1.3843] >> eta: 2359.15 secs
completed | sup_loss_l => i: [0.1597] v: [0.1308] t: [0.1196] ivt: [0.0315] >> eta: 2359.15 secs
completed | sup_loss_r => i: [0.1803] v: [0.1830] t: [0.1496] ivt: [0.0349] >> eta: 2359.15 secs
Evaluating @ epoch:  2
>>> Saving checkpoint for epoch 3 at /home/jhuangcj/tom/rend/__checkpoint__/run_2/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth, time Fri Mar 17 13:55:01 2023 
				 video-wise | eta 46.12 secs | mAP_l => ivt: [0.07693] | mAP_r => ivt: [0.05418] 
Traning | lr_l: [[0.039999999999999994], [0.024999999999999994], [0.014655172413793103]] | lr_r: [[0.039999999999999994], [0.024999999999999994], [0.014655172413793103]] | epoch 3 | completed | cps_loss => i: [1.2504] v: [1.3372] t: [1.3225] ivt: [1.3817] >> eta: 2420.97 secs
completed | sup_loss_l => i: [0.1320] v: [0.1751] t: [0.1477] ivt: [0.0442] >> eta: 2420.97 secs
completed | sup_loss_r => i: [0.1769] v: [0.2157] t: [0.1561] ivt: [0.0447] >> eta: 2420.97 secs
Evaluating @ epoch:  3
				 video-wise | eta 45.30 secs | mAP_l => ivt: [0.09054] | mAP_r => ivt: [0.07215] 
Traning | lr_l: [[0.04999999999999999], [0.029999999999999992], [0.016206896551724137]] | lr_r: [[0.04999999999999999], [0.029999999999999992], [0.016206896551724137]] | epoch 4 | completed | cps_loss => i: [1.2498] v: [1.3067] t: [1.3270] ivt: [1.3824] >> eta: 2382.74 secs
completed | sup_loss_l => i: [0.1263] v: [0.1029] t: [0.1239] ivt: [0.0353] >> eta: 2382.74 secs
completed | sup_loss_r => i: [0.1539] v: [0.1497] t: [0.1394] ivt: [0.0398] >> eta: 2382.74 secs
Evaluating @ epoch:  4
>>> Saving checkpoint for epoch 5 at /home/jhuangcj/tom/rend/__checkpoint__/run_2/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres.pth, time Fri Mar 17 15:16:35 2023 
				 video-wise | eta 44.47 secs | mAP_l => ivt: [0.10511] | mAP_r => ivt: [0.09712] 
--------------------------------------------------
Test Results of 1st subnetwork
Per-category AP: 
I   : [0.95408807 0.85669511 0.96307215 0.25082999 0.49930303 0.59201152]
V   : [0.53959372 0.89718843 0.92508131 0.62113503 0.44753333 0.07335422
 0.29636424 0.07213825 0.02279895 0.16958437]
T   : [0.84396495 0.07741864 0.18227111 0.10424267 0.03599057        nan
 0.31588208 0.01581634 0.40041111 0.03388732 0.1220632  0.02958467
 0.02070891 0.48033671 0.14270905]
IV  : [0.5811755  0.88746126 0.00315702 0.01467952 0.13783464 0.02726054
 0.03219684 0.13157527 0.61783003 0.02862031 0.01770929 0.91432389
 0.00840559        nan 0.07358722        nan        nan 0.10044579
 0.01434573 0.33435702 0.02748203 0.03449159        nan 0.32040251
 0.03908965 0.08644476]
IT  : [0.77715315 0.11066601 0.08113865 0.0382071         nan 0.35924194
 0.16893696 0.0550873  0.03152726 0.64414019 0.13783464 0.14674543
 0.04653271 0.02282223        nan 0.01165992        nan 0.04584557
 0.6082095         nan 0.0740863         nan        nan 0.02862031
 0.64010688 0.15750468 0.17537392 0.06194622        nan        nan
 0.05026711 0.21259565 0.03588979 0.07358722        nan 0.00959936
 0.06466946 0.05454838        nan 0.02107629 0.11473574        nan
        nan 0.01434573 0.04313568 0.24139444 0.13487189        nan
        nan 0.02748203        nan        nan        nan 0.01748358
 0.32040251 0.02016591 0.04991575        nan 0.08644476]
IVT : [           nan 5.42640763e-03 5.10464523e-04 3.82070950e-02
 6.42040322e-02            nan 7.47382983e-03 1.02429124e-01
 2.72870430e-03 2.88074341e-02 3.79959833e-03            nan
 6.44140192e-01 1.46795174e-02            nan            nan
 1.63480703e-01 7.75393712e-01 3.11671382e-02 3.58489801e-01
 1.67676376e-01 5.85979999e-02 4.58455743e-02            nan
            nan 9.91674991e-03 6.40585989e-03 4.60242631e-02
 4.65104957e-02 5.46065227e-01 7.14341299e-02            nan
            nan            nan 2.41737881e-03            nan
 1.66209073e-01            nan 2.50180693e-02 3.66473915e-02
            nan 8.90393734e-03            nan            nan
 8.27326845e-03 5.26760061e-02            nan            nan
            nan            nan            nan 8.09283332e-03
 3.07738878e-03 5.16492154e-03            nan            nan
            nan 6.22045108e-02 1.75381818e-01 1.57512104e-01
 6.31260112e-01 2.03273791e-01 3.69875367e-02 1.19758867e-02
 1.08350398e-01            nan 1.14735736e-01            nan
 5.45483763e-02 6.46694633e-02 1.05829021e-02 2.10762929e-02
            nan            nan            nan            nan
            nan            nan 1.34871893e-01 2.41394437e-01
            nan 4.31356752e-02 3.20402507e-01            nan
            nan            nan            nan            nan
 2.01659050e-02 7.04122737e-03 5.11738146e-02            nan
 3.46115280e-02            nan 1.37834636e-01 2.86203134e-02
 7.35872159e-02 1.43457262e-02 2.74820308e-02 8.64447578e-02]
--------------------------------------------------
Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT 
:::::: : 0.6860 | 0.4065 | 0.2004 | 0.2015 | 0.1467 | 0.1054 
==================================================
--------------------------------------------------
Test Results of 2nd subnetwork
Per-category AP: 
I   : [0.93885914 0.82798504 0.97161796 0.24738678 0.48151701 0.58018929]
V   : [0.48481373 0.87815481 0.90518989 0.68147972 0.2687282  0.05395852
 0.20125976 0.14189393 0.30449364 0.17965474]
T   : [0.80536301 0.08115333 0.13089605 0.04880144 0.05722604        nan
 0.2521163  0.06183661 0.42103076 0.03924629 0.09228032 0.03463186
 0.02139957 0.24931632 0.13591724]
IV  : [0.45702299 0.80178007 0.00613958 0.02219386 0.13275009 0.06342858
 0.0632219  0.03587985 0.62180665 0.07197599 0.01090922 0.83999611
 0.01042169        nan 0.08371664        nan        nan 0.06624573
 0.01135586 0.25038095 0.01672996 0.0584421         nan 0.2975818
 0.08823493 0.04189523]
IT  : [0.66301786 0.0894221  0.04183383 0.04402007        nan 0.29787255
 0.12512763 0.02701608 0.02887737 0.53071946 0.13275009 0.0859397
 0.13325157 0.02488465        nan 0.01129924        nan 0.00663978
 0.5542658         nan 0.01406013        nan        nan 0.07197599
 0.54598374 0.08282267 0.1658349  0.07709468        nan        nan
 0.00552566 0.15639785 0.02279343 0.08371664        nan 0.01126539
 0.02658501 0.03742964        nan 0.0468022  0.07292721        nan
        nan 0.01135586 0.01106118 0.11341056 0.17019075        nan
        nan 0.01672996        nan        nan        nan 0.10655583
 0.2975818  0.04788541 0.07679483        nan 0.04189523]
IVT : [       nan 0.00912636 0.00104384 0.04402007 0.03664428        nan
 0.0120338  0.04604512 0.00484206 0.02058179 0.00704905        nan
 0.53071946 0.02219386        nan        nan 0.12655469 0.65829857
 0.02879737 0.29451759 0.12331707 0.02794251 0.00663978        nan
        nan 0.02243286 0.01251739 0.14217798 0.0741729  0.50803509
 0.01661916        nan        nan        nan 0.0027866         nan
 0.05726097        nan 0.02733783 0.11607757        nan 0.00342515
        nan        nan 0.09965028 0.02856816        nan        nan
        nan        nan        nan 0.01079655 0.00318418 0.00641645
        nan        nan        nan 0.07709468 0.16583535 0.08282267
 0.5360261  0.14900194 0.0229286  0.01014749 0.00670199        nan
 0.07292721        nan 0.03742964 0.02658501 0.01105045 0.0468022
        nan        nan        nan        nan        nan        nan
 0.17019075 0.11341056        nan 0.01106118 0.2975818         nan
        nan        nan        nan        nan 0.04788541 0.20916612
 0.05079564        nan 0.06399338        nan 0.13275009 0.07197599
 0.08371664 0.01135586 0.01672996 0.04189523]
--------------------------------------------------
Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT 
:::::: : 0.6746 | 0.4100 | 0.1737 | 0.1842 | 0.1247 | 0.0934 
==================================================
All done!
Shutting done...
It is what it is ...
C'est finis! ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
